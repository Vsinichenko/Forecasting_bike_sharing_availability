{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from elasticsearch_dsl import Search, Q, Range, connections\n",
    "#from elasticsearch.client import Elasticsearch\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data/events/browse_ai/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{DATA_FOLDER}df_browse_ai 2025-01-02_18-50-53.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_columns = []\n",
    "for col in df.columns:\n",
    "    if col.startswith(\"extr\"):\n",
    "        extracted_columns.append(col)\n",
    "    \n",
    "extracted_columns.append(\"isOnMultipleDays\")\n",
    "extracted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 18075\n",
    "df.loc[id, \"isOnMultipleDays\"]=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 18072\n",
    "df.loc[id, \"isOnMultipleDays\"]=False\n",
    "df.loc[id, \"extrStartTime\"]=\"11\"\n",
    "df.loc[id, \"extrEndTime\"]=\"13\"\n",
    "df.loc[id, \"extrMultipleDaysDetails\"]=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 4212\n",
    "df.loc[id, \"isOnMultipleDays\"]=False\n",
    "df.loc[id, \"extrMultipleDaysDetails\"]=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 2289\n",
    "df.loc[id, \"extrStartDate\"] = \"2024-09-13\"\n",
    "df.loc[id, \"extrEndDate\"] = \"2024-10-06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with undefined location\n",
    "flt = df.extrLocationName==\"verschiedene Veranstaltungsorte\"\n",
    "df = df[~flt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = []\n",
    "for col in df.columns:\n",
    "    if col.startswith(\"OpenAI\") or col.startswith(\"count_\") :\n",
    "        cols_to_remove.append(col)\n",
    "    \n",
    "df = df.drop(columns=cols_to_remove, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = (df.isOnMultipleDays==True) \n",
    "df_multiple_days = df[flt].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose missng end date in 2 weeks after start \n",
    "flt = (df.isOnMultipleDays==True) & (df.extrEndDate.isna() ) \n",
    "values = df.loc[flt, \"extrStartDate\"]\n",
    "values = (pd.to_datetime(values) + pd.DateOffset(weeks=2)).dt.strftime(\"%Y-%m-%d\")\n",
    "values\n",
    "df.loc[flt, \"extrEndDate\"] = values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if end date is after 2024-10-31, set it to 2024-10-31\n",
    "flt = (df.isOnMultipleDays==True) & (pd.to_datetime(df.extrEndDate) > pd.to_datetime(\"2024-10-31\") )\n",
    "df.loc[flt, \"extrEndDate\"]=\"2024-10-31\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 4931\n",
    "df.loc[id, \"extrStartTime\"]=\"20\"\n",
    "df.loc[id, \"extrEndTime\"]=\"23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 6155\n",
    "df.loc[id, \"extrEndTime\"]=\"22,5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 3156\n",
    "df.loc[id, \"extrStartTime\"]=\"15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "id= 18582\n",
    "df.loc[id, \"extrStartTime\"]=\"15\"\n",
    "df.loc[id, \"extrEndTime\"]=\"16,5\"\n",
    "id=22687\n",
    "df.loc[id, \"extrStartTime\"]=\"15\"\n",
    "df.loc[id, \"extrEndTime\"]=\"16,5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 24499\n",
    "df.loc[id, \"extrStartTime\"]=\"13\"\n",
    "df.loc[id, \"extrEndTime\"]=\"20,5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 10469\n",
    "df.loc[id, \"extrLocationName\"]=\"MÃ¼nsterplatz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 18075\n",
    "df.loc[id, \"extrMultipleDaysDetails\"]=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.extrStartTime.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df.extrStartTime.str.endswith(\":00\", na=False)\n",
    "values = df.loc[flt, \"extrStartTime\"].str.replace(\":00\", \"\")\n",
    "values\n",
    "df.loc[flt, \"extrStartTime\"] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df.extrEndTime.str.endswith(\":00\", na=False)\n",
    "values = df.loc[flt, \"extrEndTime\"].str.replace(\":00\", \"\")\n",
    "values\n",
    "df.loc[flt, \"extrEndTime\"] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df.extrEndTime.str.endswith(\":30\", na=False)\n",
    "values = df.loc[flt, \"extrEndTime\"].str.replace(\":30\", \",5\")\n",
    "values\n",
    "df.loc[flt, \"extrEndTime\"] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df.extrEndTime.str.endswith(\":45\", na=False)\n",
    "values = df.loc[flt, \"extrEndTime\"].str.replace(\":45\", \",5\")\n",
    "values\n",
    "df.loc[flt, \"extrEndTime\"] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.extrEndTime = df.extrEndTime.str.replace(\"19:00 (weekdays), 18:00 (weekends & holidays)\", \"19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df.extrStartTime.str.contains(\"Termin/Uhrzeit\", na=False)\n",
    "values = df.loc[flt, \"extrStartTime\"].apply(lambda ls: ls.split(\"\\n\")[-1]).str.replace(\" Uhr\", \"\").str.replace(\":00\", \"\").str.replace(\":30\", \",5\")\n",
    "values\n",
    "df.loc[flt, \"extrStartTime\"] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.extrStartTime = df.extrStartTime.str.replace(\":00 (for the opening ceremony)\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.extrStartTime.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.extrEndTime.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[3156, \"extrEndTime\"]=\"18\"\n",
    "df.loc[5495, \"extrEndTime\"]=\"18\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate the readiness of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_columns = []\n",
    "for col in df.columns:\n",
    "    if col.startswith(\"extr\"):\n",
    "        extracted_columns.append(col)\n",
    "    \n",
    "extracted_columns.append(\"isOnMultipleDays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = (df.isOnMultipleDays==False) \n",
    "print(\"total single-day events\")\n",
    "print(len(df[flt]))\n",
    "for col in extracted_columns:\n",
    "    flt_2 = df[col].isna()\n",
    "    print(col+ \" has missing rows:\")\n",
    "    print(len(df[flt&flt_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = (df.isOnMultipleDays==True) \n",
    "print(\"total multiple-day events\")\n",
    "print(len(df[flt]))\n",
    "for col in extracted_columns:\n",
    "    flt_2 = df[col].isna()\n",
    "    print(col+ \" has missing rows:\")\n",
    "    print(len(df[flt&flt_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flt = (df.isOnMultipleDays==True) & (df.extrLocationName.isna())  & (df.extrLocationDetails.isna())\n",
    "#df.loc[flt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = f\"{DATA_FOLDER}df_browse_ai {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"\n",
    "#print(filename)\n",
    "#df.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform multiple events into single events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_process = df.copy()\n",
    "df_to_process =  df_to_process.reset_index(names=\"origin_id\")\n",
    "\n",
    "df_to_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = extracted_columns.copy()\n",
    "cols_to_keep.append(\"origin_id\")\n",
    "cols_to_keep.append(\"Event_category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_process = df_to_process[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols_except_id = df_to_process.columns.tolist()\n",
    "all_cols_except_id.remove(\"origin_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_process.drop_duplicates(inplace=True, subset=all_cols_except_id)\n",
    "len(df_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_process.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df_to_process.isOnMultipleDays==False\n",
    "df_final = df_to_process[flt].copy()\n",
    "df_to_process = df_to_process[~flt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_process.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with existing start and end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = (~df_to_process.extrStartDate.isna()) & (~df_to_process.extrEndDate.isna()) & (~df_to_process.extrStartTime.isna()) & (~df_to_process.extrEndTime.isna())\n",
    "df_tmp = df_to_process[flt].copy()\n",
    "df_to_process = df_to_process[~flt]\n",
    "df_tmp\n",
    "# expand multiple day events to single day events\n",
    "df_tmp[\"extrStartDate\"] = pd.to_datetime(df_tmp[\"extrStartDate\"])\n",
    "df_tmp[\"extrEndDate\"] = pd.to_datetime(df_tmp[\"extrEndDate\"])\n",
    "df_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_append = []\n",
    "for i, row in df_tmp.iterrows():\n",
    "    start_date = row[\"extrStartDate\"]\n",
    "    end_date = row[\"extrEndDate\"]\n",
    "    print(f\"{start_date=}\")\n",
    "    print(f\"{end_date=}\")\n",
    "    date_range = pd.date_range(start_date, end_date)\n",
    "    \n",
    "    for date in date_range: # inclusive range\n",
    "        row_to_append = row.copy()\n",
    "        row_to_append[\"extrEndDate\"] = None\n",
    "        row_to_append[\"extrStartDate\"] = date.strftime('%Y-%m-%d')\n",
    "        rows_to_append.append(row_to_append)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_append = pd.DataFrame(rows_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_final, df_to_append])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with missing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/keys/OpenAIKey (vkalonova).txt\", \"r\") as file:\n",
    "        openai_api_key = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\" Give me a record of date, start and end times of events for each date in which an event happens. Taake weekdays onto account.\n",
    "Example input:\n",
    "2024-10-03 till 2024-10-06\n",
    "MultipleDaysDetails = Thu: 10:00-20:00, Fri: 11:00-19:00, Sat: 10:00-20:00, Sun: 10:00-20:00\n",
    "Example output:\n",
    "2024-10-03, 10:00-20:00\n",
    "2024-10-04, 11:00,-19:00\n",
    "2024-10-05, 10:00-20:00\n",
    "2024-10-06, 10:00-20:00\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 41\n",
    "prompt = f\"\"\" {df_to_process.loc[id, \"extrStartDate\"]} till {df_to_process.loc[id, \"extrEndDate\"]}\n",
    "MultipleDaysDetails = {df_to_process.loc[id, \"extrMultipleDaysDetails\"]}\n",
    "\"\"\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_respones = []\n",
    "openai_respones.append({ \"id\": 41, \"response\": completion.choices[0].message.content})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_to_process.iterrows():\n",
    "    print(i)\n",
    "    print()\n",
    "    if i==41:\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        prompt = f\"\"\" {df_to_process.loc[i, \"extrStartDate\"]} till {df_to_process.loc[i, \"extrEndDate\"]}\n",
    "MultipleDaysDetails = {df_to_process.loc[i, \"extrMultipleDaysDetails\"]}\"\"\"\n",
    "        print(prompt)\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_content},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        res = completion.choices[0].message.content\n",
    "        print(res)\n",
    "\n",
    "        openai_respones.append({ \"id\": i, \"response\": completion.choices[0].message.content})\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openai_responses = pd.DataFrame(openai_respones)\n",
    "df_openai_responses.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openai_responses[\"processed_response\"] = df_openai_responses.response.apply(lambda x: x.split(\"\\n\")).apply(lambda x: [i for i in x if \"2024\" in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openai_responses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process openai responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_append = []\n",
    "skipped_rows = 0\n",
    "openai_explanations = [\"Now let's\", \"To accurately provide\", \"We need to consider\", \"To provide a schedule\", \"Continuing in this \",\n",
    "                       \"Identify\", \"Check\", \"To determine\", \"map these details\", \"Given the provided input\", \"If the day is\", \"To create a schedule\",\n",
    "                       \"Note that\", \"To provide\"]\n",
    "closed_events_escriptions = [\"Closed\", \"No event\", \"geschlossen\", \"No event\"]\n",
    "holiday_descriptions = [\"Thursday - Tag der Deutschen Einheit\", \" (Holiday - Labor Day)\", \n",
    "                        \"Thursday, Halloween; not a public holiday\", \"German Unity Day, public holiday\",\n",
    "                        \"Feiertag in Deutschland: Tag der Deutschen Einheit\", \"Tag der Deutschen Einheit\", \"(\", \")\"\n",
    "                        ]\n",
    "for _, openai_row in df_openai_responses.iterrows():\n",
    "    single_dates_responses = openai_row[\"response\"].split(\"\\n\")\n",
    "    # only keep elemets in a list with at least 1 digit\n",
    "\n",
    "    for res in single_dates_responses:\n",
    "        res = res.replace(\"**\", \"\")\n",
    "        for full_german_weekday in [\", Montag, \", \", Dienstag, \", \", Mittwoch, \", \", Donnerstag, \", \", Freitag, \", \", Samstag, \", \", Sonntag, \"]:\n",
    "                res = res.replace(full_german_weekday, \", \")\n",
    "        for full_german_weekday in [\" (Monday): \", \" (Tuesday): \", \" (Wednesday): \", \" (Thursday): \", \" (Friday): \", \" (Saturday): \", \" (Sunday): \"]:\n",
    "                res = res.replace(full_german_weekday, \", \")\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        for full_weekday in [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]:\n",
    "            res = res.replace(full_weekday, \"\")\n",
    "        \n",
    "        for weekday in [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]:\n",
    "            res = res.replace(weekday, \"\")\n",
    "        res = res.replace(\", , \", \", \")\n",
    "        res = res.replace(\" (): \", \", \") \"\"\"\n",
    "        for txt in holiday_descriptions:\n",
    "            res = res.replace(txt, \"\")\n",
    "        res = res.replace(\"  \", \" \")\n",
    "\n",
    "        skip_outer_loop = False\n",
    "        if not re.search(r\"\\d\", res):\n",
    "            continue\n",
    "        for txt in openai_explanations:\n",
    "            if txt in res:\n",
    "                skip_outer_loop=True\n",
    "                break \n",
    "        for txt in closed_events_escriptions:\n",
    "            if txt in res:\n",
    "                skip_outer_loop=True\n",
    "                break\n",
    "\n",
    "        if skip_outer_loop:\n",
    "            continue\n",
    "        try:\n",
    "            date, times1, times2, times3 = res.split(\", \")\n",
    "            start_time1, end_time1 = times1.split(\"-\")\n",
    "            start_time1 = start_time1.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "            end_time1 = end_time1.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "            start_time2, end_time2 = times2.split(\"-\")\n",
    "            start_time2 = start_time2.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "            end_time2 = end_time2.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "            start_time3 = times3\n",
    "            end_time3 = None\n",
    "            id = openai_row[\"id\"]\n",
    "            assert len(df_to_process[df_to_process.index == id]) == 1\n",
    "            row_to_append = df_to_process.loc[id].copy()\n",
    "            row_to_append[\"extrStartDate\"] = date\n",
    "            row_to_append[\"extrEndDate\"] = None\n",
    "            row_to_append[\"extrStartTime\"] = start_time1\n",
    "            row_to_append[\"extrEndTime\"] = end_time1\n",
    "            rows_to_append.append(row_to_append)\n",
    "            row_to_append = df_to_process.loc[id].copy()\n",
    "            row_to_append[\"extrStartDate\"] = date\n",
    "            row_to_append[\"extrEndDate\"] = None \n",
    "            row_to_append[\"extrStartTime\"] = start_time2\n",
    "            row_to_append[\"extrEndTime\"] = end_time2\n",
    "            rows_to_append.append(row_to_append)\n",
    "            row_to_append = df_to_process.loc[id].copy()\n",
    "            row_to_append[\"extrStartDate\"] = date\n",
    "            row_to_append[\"extrEndDate\"] = None\n",
    "            row_to_append[\"extrStartTime\"] = start_time3\n",
    "            row_to_append[\"extrEndTime\"] = end_time3\n",
    "            rows_to_append.append(row_to_append)\n",
    "        except Exception as e:            \n",
    "            try:\n",
    "                try:    \n",
    "                    date, times1, times2 = res.split(\", \")\n",
    "                    start_time1, end_time1 = times1.split(\"-\")\n",
    "                    start_time1 = start_time1.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "                    end_time1 = end_time1.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "                    start_time2, end_time2 = times2.split(\"-\")\n",
    "                    start_time2 = start_time2.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "                    end_time2 = end_time2.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "                    id = openai_row[\"id\"]\n",
    "                    assert len(df_to_process[df_to_process.index == id]) == 1\n",
    "                    row_to_append = df_to_process.loc[id].copy()\n",
    "                    row_to_append[\"extrStartDate\"] = date\n",
    "                    row_to_append[\"extrEndDate\"] = None\n",
    "                    row_to_append[\"extrStartTime\"] = start_time1\n",
    "                    row_to_append[\"extrEndTime\"] = end_time1\n",
    "                    rows_to_append.append(row_to_append)\n",
    "                    row_to_append = df_to_process.loc[id].copy()\n",
    "                    row_to_append[\"extrStartDate\"] = date\n",
    "                    row_to_append[\"extrEndDate\"] = None\n",
    "                    row_to_append[\"extrStartTime\"] = start_time2\n",
    "                    row_to_append[\"extrEndTime\"] = end_time2\n",
    "                    rows_to_append.append(row_to_append)\n",
    "\n",
    "                # write a regexp for dates like this October 1, 2024, 10:00-18:00\n",
    "                #if re.search(res, r\"\\d{4}-\\d{2}-\\d{2}\"):\n",
    "\n",
    "                except Exception as e:\n",
    "                    date, times = res.split(\", \")\n",
    "                    #print(f\"{date=}\")\n",
    "                    #print(f\"{times=}\")\n",
    "                    start_time, end_time = times.split(\"-\")\n",
    "                    start_time = start_time.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "                    end_time = end_time.strip().replace(\":00\", \"\").replace(\":30\", \",5\")\n",
    "                    #print(f\"{start_time=}\")\n",
    "                    #print(f\"{end_time=}\")\n",
    "                    id = openai_row[\"id\"]\n",
    "                    #print(f\"{id=}\")\n",
    "                    assert len(df_to_process[df_to_process.index == id]) == 1\n",
    "                    row_to_append = df_to_process.loc[id].copy()\n",
    "                    #print(f\"{row_to_append=}\")\n",
    "                    row_to_append[\"extrStartDate\"] = date\n",
    "                    row_to_append[\"extrEndDate\"] = None\n",
    "                    row_to_append[\"extrStartTime\"] = start_time\n",
    "                    row_to_append[\"extrEndTime\"] = end_time\n",
    "                    rows_to_append.append(row_to_append)\n",
    "            except Exception as e:\n",
    "                print(f\"could not process {res} because of {e}\")\n",
    "                skipped_rows += 1\n",
    "                print(f\"extrMultipleDaysDetails: {   df_to_process.loc[id, 'extrMultipleDaysDetails']}\")\n",
    "                print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_append =  pd.DataFrame(rows_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_append.extrEndTime.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_append.extrStartTime.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df_to_append.extrStartDate.str.startswith(\"- \")\n",
    "values = df_to_append.loc[flt, \"extrStartDate\"].str.replace(\"- \", \"\")\n",
    "df_to_append.loc[flt, \"extrStartDate\"] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weekday in [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]:\n",
    "    df_to_append.extrStartDate = df_to_append.extrStartDate.str.replace(weekday, \"\")\n",
    "    df_to_append.extrEndTime = df_to_append.extrEndTime.str.replace(weekday, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_append.extrStartDate =  df_to_append.extrStartDate.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_append.extrStartDate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df_to_append.extrStartDate.str.contains(\"2024\", na=False)\n",
    "df_to_append = df_to_append[flt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_append.extrStartTime = df_to_append.extrStartTime.str.replace(\":30\", \",5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df_to_append.extrStartTime.str.contains(\"Feiertag\")\n",
    "df_to_append = df_to_append[~flt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_append.extrStartTime.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_append.extrEndTime.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = df_to_append.extrEndTime.str.contains(\"Closing\", na=False)\n",
    "df_to_append = df_to_append[~flt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df_final, df_to_append])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_final = df_final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.dropna(how=\"all\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"Source\"]=\"browse_ai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel(f\"{DATA_FOLDER}df_browse_ai {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(f\"{DATA_FOLDER}df_browse_ai final {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_pickle(f\"{DATA_FOLDER}df_browse_ai final {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Forecasting_bike_sharing_availability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
