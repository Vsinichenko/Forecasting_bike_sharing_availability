{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bike trips\n",
    "filename_DD = f\"../data/nextbike/hourly_demand_supply_Dresden 2025-03-19_10-47-56.csv\"\n",
    "filename_FB = f\"../data/nextbike/hourly_demand_supply_Freiburg_missing_interpolated_2025-03-19_10-47-56.csv\"\n",
    "df_DD = pd.read_csv(filename_DD, index_col=None, parse_dates=[\"datetime_hour\"])\n",
    "df_FB = pd.read_csv(filename_FB, index_col=None, parse_dates=[\"datetime_hour\"])\n",
    "df_DD = df_DD.sort_values(\"datetime_hour\")\n",
    "df_FB = df_FB.sort_values(\"datetime_hour\")\n",
    "# events \n",
    "filename_events = \"../data/events/df_events_with_hex_id_2025-04-08_13-38-19.csv\"\n",
    "df_events = pd.read_csv(filename_events, index_col=None, parse_dates=[\"StartDateTime\", \"EndDateTime\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_len_df_DD = len(df_DD)\n",
    "initial_len_df_FB = len(df_FB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather\n",
    "filename_weather_DD = \"../data/weather/df_Dresden_weather_hourly 2025-03-28_20-51-37.csv\"\n",
    "filename_weather_FB = \"../data/weather/df_Freiburg_weather_hourly 2025-03-28_20-51-37.csv\"\n",
    "\n",
    "df_weather_DD = pd.read_csv(filename_weather_DD, index_col=None, parse_dates=[\"datetime_hour\"])\n",
    "df_weather_FB = pd.read_csv(filename_weather_FB, index_col=None, parse_dates=[\"datetime_hour\"])\n",
    "\n",
    "df_DD = df_DD.merge(df_weather_DD, on=\"datetime_hour\", how=\"left\")\n",
    "df_FB = df_FB.merge(df_weather_FB, on=\"datetime_hour\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calendar effects\n",
    "for i, df_tmp in enumerate([df_DD, df_FB]):\n",
    "    df_tmp[\"weekday\"] = df_tmp.datetime_hour.dt.dayofweek\n",
    "    df_tmp[\"weekday\"] = df_tmp[\"weekday\"].map({0: \"Mon\", 1: \"Tue\", 2: \"Wed\", 3: \"Thu\", 4: \"Fri\", 5: \"Sat\", 6: \"Sun\"})\n",
    "    weekday_df = pd.get_dummies(df_tmp[\"weekday\"], prefix=\"weekday\", drop_first=False, dtype=int)\n",
    "    weekday_df.index = df_tmp.index\n",
    "    weekday_df.drop(columns=\"weekday_Mon\", inplace=True)\n",
    "    df_tmp[weekday_df.columns] = weekday_df\n",
    "\n",
    "    df_tmp[\"is_dayoff\"] = df_tmp[\"weekday_Sat\"] + df_tmp[\"weekday_Sun\"]\n",
    "    # list of german holidays in 2023 and 2024\n",
    "    if i == 0:\n",
    "        # holidays for Dresden\n",
    "        german_holidays = [\"2024-01-01\", \"2024-03-29\", \"2024-04-01\", \"2024-05-01\", \"2024-05-09\", \"2024-05-20\", \"2024-10-03\", \"2024-10-31\"]\n",
    "    else:\n",
    "        german_holidays = [\"2023-06-08\", \"2024-10-03\"]\n",
    "    german_holidays = [pd.to_datetime(date).date() for date in german_holidays]\n",
    "    flt = df_tmp.datetime_hour.dt.date.isin(german_holidays)\n",
    "    len(df_tmp[flt])\n",
    "    df_tmp.loc[flt, \"is_dayoff\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[\"StartDateTime_adj\"] = df_events.StartDateTime.apply(lambda x: x-timedelta(hours=1) if x.hour == 0 else x.floor(\"H\"))\n",
    "df_events.query(\"StartDateTime_adj != StartDateTime\")[[\"StartDateTime\", \"StartDateTime_adj\"]]\n",
    "df_events[\"EndDateTime_adj\"] = df_events.EndDateTime.apply(lambda x: x if x.hour == 0 else x.floor(\"H\"))\n",
    "df_events_grouped_start = df_events.groupby([\"hex_id\", \"StartDateTime_adj\"]).size().reset_index(name=\"event_count_start\")\n",
    "df_events_grouped_end = df_events.dropna(subset=[\"EndDateTime_adj\"]).groupby([\"hex_id\", \"EndDateTime_adj\"]).size().reset_index(name=\"event_count_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DD = df_DD.merge(df_events_grouped_start, how=\"left\", left_on=[\"datetime_hour\", \"hex_id\"], right_on=[\"StartDateTime_adj\", \"hex_id\"], indicator=False)\n",
    "df_DD.event_count_start.fillna(0, inplace=True)\n",
    "df_DD = df_DD.merge(df_events_grouped_end, how=\"left\", left_on=[\"datetime_hour\", \"hex_id\"], right_on=[\"EndDateTime_adj\", \"hex_id\"], indicator=False)\n",
    "df_DD.drop(columns=[\"StartDateTime_adj\", \"EndDateTime_adj\"], inplace=True, errors=\"ignore\")\n",
    "df_DD.event_count_end.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FB = df_FB.merge(df_events_grouped_start, how=\"left\", left_on=[\"datetime_hour\", \"hex_id\"], right_on=[\"StartDateTime_adj\", \"hex_id\"], indicator=False)\n",
    "df_FB.event_count_start.fillna(0, inplace=True)\n",
    "df_FB = df_FB.merge(df_events_grouped_end, how=\"left\", left_on=[\"datetime_hour\", \"hex_id\"], right_on=[\"EndDateTime_adj\", \"hex_id\"], indicator=False)\n",
    "df_FB.drop(columns=[\"StartDateTime_adj\", \"EndDateTime_adj\"], inplace=True, errors=\"ignore\")\n",
    "df_FB.event_count_end.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_DD) == initial_len_df_DD\n",
    "assert len(df_FB) == initial_len_df_FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DD = df_DD.sort_values(\"datetime_hour\")\n",
    "df_FB = df_FB.sort_values(\"datetime_hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "df_DD.to_csv(f\"../data/df_DD_{time}.csv\", index=False)\n",
    "df_FB.to_csv(f\"../data/df_FB_{time}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Forecasting_bike_sharing_availability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
